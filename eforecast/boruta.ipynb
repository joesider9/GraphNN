{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-26T09:01:39.501428Z",
     "start_time": "2025-05-26T09:01:38.011898Z"
    }
   },
   "source": [
    "import os\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from boruta import BorutaPy\n",
    "from lightgbm import LGBMRegressor\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-26T09:04:50.528798Z",
     "start_time": "2025-05-26T09:04:50.395001Z"
    }
   },
   "cell_type": "code",
   "source": [
    "file_x = '/media/smartrue/HHD1/George/models/PPC/PPC_sat_ver0/pv/Ptolemaida/multi-output/model_ver0/DATA/dataset_row_data.pickle'\n",
    "file_y = '/media/smartrue/HHD1/George/models/PPC/PPC_sat_ver0/pv/Ptolemaida/multi-output/model_ver0/DATA/dataset_target_data.csv'\n",
    "data_x = joblib.load(file_x)['row_stats']\n",
    "data_y = pd.read_csv(file_y, index_col=0, header=0, parse_dates=True)"
   ],
   "id": "3ccab1be34479b4",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-26T10:31:34.334075Z",
     "start_time": "2025-05-26T10:31:34.247647Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dates = data_x.dropna(axis='index', how='any').index.intersection(data_y.dropna(axis='index', how='any').index)\n",
    "x = data_x.loc[dates].values\n",
    "y = data_y.loc[dates].values"
   ],
   "id": "3497c74a486a1eb9",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-26T10:33:03.354773Z",
     "start_time": "2025-05-26T10:33:03.248880Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "x_ = scaler.fit_transform(x)\n",
    "scaler_y = MinMaxScaler()\n",
    "y_ = scaler_y.fit_transform(y)"
   ],
   "id": "a8c9fe85682abd8b",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-26T10:38:46.834871Z",
     "start_time": "2025-05-26T10:38:46.809137Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.utils import check_random_state\n",
    "\n",
    "class BorutaPyForLGB(BorutaPy):\n",
    "    def __init__(self, estimator, n_estimators=1000, perc=100, alpha=0.05,\n",
    "                 two_step=True, max_iter=100, random_state=None, verbose=0):\n",
    "        super().__init__(estimator, n_estimators, perc, alpha,\n",
    "                         two_step, max_iter, random_state, verbose)\n",
    "        self._is_lightgbm = 'lightgbm' in str(type(self.estimator))\n",
    "\n",
    "    def _fit(self, X, y):\n",
    "        # check input params\n",
    "        self._check_params(X, y)\n",
    "\n",
    "        if not isinstance(X, np.ndarray):\n",
    "            X = self._validate_pandas_input(X)\n",
    "        if not isinstance(y, np.ndarray):\n",
    "            y = self._validate_pandas_input(y)\n",
    "\n",
    "        self.random_state = check_random_state(self.random_state)\n",
    "        # setup variables for Boruta\n",
    "        n_sample, n_feat = X.shape\n",
    "        _iter = 1\n",
    "        # holds the decision about each feature:\n",
    "        # 0  - default state = tentative in original code\n",
    "        # 1  - accepted in original code\n",
    "        # -1 - rejected in original code\n",
    "        dec_reg = np.zeros(n_feat, dtype=np.int32)\n",
    "        # counts how many times a given feature was more important than\n",
    "        # the best of the shadow features\n",
    "        hit_reg = np.zeros(n_feat, dtype=np.int32)\n",
    "        # these record the history of the iterations\n",
    "        imp_history = np.zeros(n_feat, dtype=np.float32)\n",
    "        sha_max_history = []\n",
    "\n",
    "        # set n_estimators\n",
    "        if self.n_estimators != 'auto':\n",
    "            self.estimator.set_params(n_estimators=self.n_estimators)\n",
    "\n",
    "        # main feature selection loop\n",
    "        while np.any(dec_reg == 0) and _iter < self.max_iter:\n",
    "            # find optimal number of trees and depth\n",
    "            if self.n_estimators == 'auto':\n",
    "                # number of features that aren't rejected\n",
    "                not_rejected = np.where(dec_reg >= 0)[0].shape[0]\n",
    "                n_tree = self._get_tree_num(not_rejected)\n",
    "                self.estimator.set_params(n_estimators=n_tree)\n",
    "\n",
    "            # make sure we start with a new tree in each iteration\n",
    "            if self._is_lightgbm:\n",
    "                self.estimator.set_params(random_state=self.random_state.randint(0, 10000))\n",
    "            else:\n",
    "                self.estimator.set_params(random_state=self.random_state)\n",
    "\n",
    "            # add shadow attributes, shuffle them and train estimator, get imps\n",
    "            cur_imp = self._add_shadows_get_imps(X, y, dec_reg)\n",
    "\n",
    "            # get the threshold of shadow importances we will use for rejection\n",
    "            imp_sha_max = np.percentile(cur_imp[1], self.perc)\n",
    "\n",
    "            # record importance history\n",
    "            sha_max_history.append(imp_sha_max)\n",
    "            imp_history = np.vstack((imp_history, cur_imp[0]))\n",
    "\n",
    "            # register which feature is more imp than the max of shadows\n",
    "            hit_reg = self._assign_hits(hit_reg, cur_imp, imp_sha_max)\n",
    "\n",
    "            # based on hit_reg we check if a feature is doing better than\n",
    "            # expected by chance\n",
    "            dec_reg = self._do_tests(dec_reg, hit_reg, _iter)\n",
    "\n",
    "            # print out confirmed features\n",
    "            if self.verbose > 0 and _iter < self.max_iter:\n",
    "                self._print_results(dec_reg, _iter, 0)\n",
    "            if _iter < self.max_iter:\n",
    "                _iter += 1\n",
    "\n",
    "        # we automatically apply R package's rough fix for tentative ones\n",
    "        confirmed = np.where(dec_reg == 1)[0]\n",
    "        tentative = np.where(dec_reg == 0)[0]\n",
    "        # ignore the first row of zeros\n",
    "        tentative_median = np.median(imp_history[1:, tentative], axis=0)\n",
    "        # which tentative to keep\n",
    "        tentative_confirmed = np.where(tentative_median\n",
    "                                       > np.median(sha_max_history))[0]\n",
    "        tentative = tentative[tentative_confirmed]\n",
    "\n",
    "        # basic result variables\n",
    "        self.n_features_ = confirmed.shape[0]\n",
    "        self.support_ = np.zeros(n_feat, dtype=np.bool_)\n",
    "        self.support_[confirmed] = 1\n",
    "        self.support_weak_ = np.zeros(n_feat, dtype=np.bool_)\n",
    "        self.support_weak_[tentative] = 1\n",
    "\n",
    "        # ranking, confirmed variables are rank 1\n",
    "        self.ranking_ = np.ones(n_feat, dtype=np.int32)\n",
    "        # tentative variables are rank 2\n",
    "        self.ranking_[tentative] = 2\n",
    "        # selected = confirmed and tentative\n",
    "        selected = np.hstack((confirmed, tentative))\n",
    "        # all rejected features are sorted by importance history\n",
    "        not_selected = np.setdiff1d(np.arange(n_feat), selected)\n",
    "        # large importance values should rank higher = lower ranks -> *(-1)\n",
    "        imp_history_rejected = imp_history[1:, not_selected] * -1\n",
    "\n",
    "        # update rank for not_selected features\n",
    "        if not_selected.shape[0] > 0:\n",
    "                # calculate ranks in each iteration, then median of ranks across feats\n",
    "                iter_ranks = self._nanrankdata(imp_history_rejected, axis=1)\n",
    "                rank_medians = np.nanmedian(iter_ranks, axis=0)\n",
    "                ranks = self._nanrankdata(rank_medians, axis=0)\n",
    "\n",
    "                # set smallest rank to 3 if there are tentative feats\n",
    "                if tentative.shape[0] > 0:\n",
    "                    ranks = ranks - np.min(ranks) + 3\n",
    "                else:\n",
    "                    # and 2 otherwise\n",
    "                    ranks = ranks - np.min(ranks) + 2\n",
    "                self.ranking_[not_selected] = ranks\n",
    "        else:\n",
    "            # all are selected, thus we set feature supports to True\n",
    "            self.support_ = np.ones(n_feat, dtype=np.bool_)\n",
    "\n",
    "        self.importance_history_ = imp_history\n",
    "\n",
    "        # notify user\n",
    "        if self.verbose > 0:\n",
    "            self._print_results(dec_reg, _iter, 1)\n",
    "        return self"
   ],
   "id": "93b7546cc69e8701",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-26T10:39:39.370481Z",
     "start_time": "2025-05-26T10:39:39.213833Z"
    }
   },
   "cell_type": "code",
   "source": [
    "lgb = LGBMRegressor(num_boost_round=100)\n",
    "boruta =  BorutaPyForLGB(lgb, n_estimators='auto', verbose=0, random_state=1)\n",
    "boruta.fit(x_, y_[:, 0])"
   ],
   "id": "915577b3673c8ccd",
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Please check your X and y variable. The provided estimator cannot be fitted to your data.\nnum_boost_round must be greater than 0. Got -1341.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "File \u001B[0;32m~/pytorch_env/lib/python3.10/site-packages/boruta/boruta_py.py:475\u001B[0m, in \u001B[0;36mBorutaPy._get_imp\u001B[0;34m(self, X, y)\u001B[0m\n\u001B[1;32m    474\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 475\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mestimator\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    476\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "File \u001B[0;32m~/pytorch_env/lib/python3.10/site-packages/lightgbm/sklearn.py:1189\u001B[0m, in \u001B[0;36mLGBMRegressor.fit\u001B[0;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_init_score, eval_metric, feature_name, categorical_feature, callbacks, init_model)\u001B[0m\n\u001B[1;32m   1188\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Docstring is inherited from the LGBMModel.\"\"\"\u001B[39;00m\n\u001B[0;32m-> 1189\u001B[0m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1190\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1191\u001B[0m \u001B[43m    \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1192\u001B[0m \u001B[43m    \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msample_weight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1193\u001B[0m \u001B[43m    \u001B[49m\u001B[43minit_score\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minit_score\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1194\u001B[0m \u001B[43m    \u001B[49m\u001B[43meval_set\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43meval_set\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1195\u001B[0m \u001B[43m    \u001B[49m\u001B[43meval_names\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43meval_names\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1196\u001B[0m \u001B[43m    \u001B[49m\u001B[43meval_sample_weight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43meval_sample_weight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1197\u001B[0m \u001B[43m    \u001B[49m\u001B[43meval_init_score\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43meval_init_score\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1198\u001B[0m \u001B[43m    \u001B[49m\u001B[43meval_metric\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43meval_metric\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1199\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfeature_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfeature_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1200\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcategorical_feature\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcategorical_feature\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1201\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallbacks\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1202\u001B[0m \u001B[43m    \u001B[49m\u001B[43minit_model\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minit_model\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1203\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1204\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\n",
      "File \u001B[0;32m~/pytorch_env/lib/python3.10/site-packages/lightgbm/sklearn.py:955\u001B[0m, in \u001B[0;36mLGBMModel.fit\u001B[0;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, feature_name, categorical_feature, callbacks, init_model)\u001B[0m\n\u001B[1;32m    953\u001B[0m callbacks\u001B[38;5;241m.\u001B[39mappend(record_evaluation(evals_result))\n\u001B[0;32m--> 955\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_Booster \u001B[38;5;241m=\u001B[39m \u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    956\u001B[0m \u001B[43m    \u001B[49m\u001B[43mparams\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    957\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtrain_set\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrain_set\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    958\u001B[0m \u001B[43m    \u001B[49m\u001B[43mnum_boost_round\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mn_estimators\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    959\u001B[0m \u001B[43m    \u001B[49m\u001B[43mvalid_sets\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvalid_sets\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    960\u001B[0m \u001B[43m    \u001B[49m\u001B[43mvalid_names\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43meval_names\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    961\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfeval\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43meval_metrics_callable\u001B[49m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# type: ignore[arg-type]\u001B[39;49;00m\n\u001B[1;32m    962\u001B[0m \u001B[43m    \u001B[49m\u001B[43minit_model\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minit_model\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    963\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallbacks\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    964\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    966\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_evals_result \u001B[38;5;241m=\u001B[39m evals_result\n",
      "File \u001B[0;32m~/pytorch_env/lib/python3.10/site-packages/lightgbm/engine.py:173\u001B[0m, in \u001B[0;36mtrain\u001B[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, feval, init_model, feature_name, categorical_feature, keep_training_booster, callbacks)\u001B[0m\n\u001B[1;32m    172\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m num_boost_round \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m--> 173\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnum_boost_round must be greater than 0. Got \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mnum_boost_round\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    175\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(valid_sets, \u001B[38;5;28mlist\u001B[39m):\n",
      "\u001B[0;31mValueError\u001B[0m: num_boost_round must be greater than 0. Got -1341.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[19], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m lgb \u001B[38;5;241m=\u001B[39m LGBMRegressor(num_boost_round\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m100\u001B[39m)\n\u001B[1;32m      2\u001B[0m boruta \u001B[38;5;241m=\u001B[39m  BorutaPyForLGB(lgb, n_estimators\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mauto\u001B[39m\u001B[38;5;124m'\u001B[39m, verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m, random_state\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m----> 3\u001B[0m \u001B[43mboruta\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx_\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_\u001B[49m\u001B[43m[\u001B[49m\u001B[43m:\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/pytorch_env/lib/python3.10/site-packages/boruta/boruta_py.py:222\u001B[0m, in \u001B[0;36mBorutaPy.fit\u001B[0;34m(self, X, y)\u001B[0m\n\u001B[1;32m    209\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mfit\u001B[39m(\u001B[38;5;28mself\u001B[39m, X, y):\n\u001B[1;32m    210\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    211\u001B[0m \u001B[38;5;124;03m    Fits the Boruta feature selection with the provided estimator.\u001B[39;00m\n\u001B[1;32m    212\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    219\u001B[0m \u001B[38;5;124;03m        The target values.\u001B[39;00m\n\u001B[1;32m    220\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 222\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_fit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[16], line 55\u001B[0m, in \u001B[0;36mBorutaPyForLGB._fit\u001B[0;34m(self, X, y)\u001B[0m\n\u001B[1;32m     52\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mestimator\u001B[38;5;241m.\u001B[39mset_params(random_state\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrandom_state)\n\u001B[1;32m     54\u001B[0m \u001B[38;5;66;03m# add shadow attributes, shuffle them and train estimator, get imps\u001B[39;00m\n\u001B[0;32m---> 55\u001B[0m cur_imp \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_add_shadows_get_imps\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdec_reg\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     57\u001B[0m \u001B[38;5;66;03m# get the threshold of shadow importances we will use for rejection\u001B[39;00m\n\u001B[1;32m     58\u001B[0m imp_sha_max \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mpercentile(cur_imp[\u001B[38;5;241m1\u001B[39m], \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mperc)\n",
      "File \u001B[0;32m~/pytorch_env/lib/python3.10/site-packages/boruta/boruta_py.py:503\u001B[0m, in \u001B[0;36mBorutaPy._add_shadows_get_imps\u001B[0;34m(self, X, y, dec_reg)\u001B[0m\n\u001B[1;32m    501\u001B[0m x_sha \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mapply_along_axis(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_shuffle, \u001B[38;5;241m0\u001B[39m, x_sha)\n\u001B[1;32m    502\u001B[0m \u001B[38;5;66;03m# get importance of the merged matrix\u001B[39;00m\n\u001B[0;32m--> 503\u001B[0m imp \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_imp\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhstack\u001B[49m\u001B[43m(\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx_cur\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx_sha\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    504\u001B[0m \u001B[38;5;66;03m# separate importances of real and shadow features\u001B[39;00m\n\u001B[1;32m    505\u001B[0m imp_sha \u001B[38;5;241m=\u001B[39m imp[x_cur_w:]\n",
      "File \u001B[0;32m~/pytorch_env/lib/python3.10/site-packages/boruta/boruta_py.py:477\u001B[0m, in \u001B[0;36mBorutaPy._get_imp\u001B[0;34m(self, X, y)\u001B[0m\n\u001B[1;32m    475\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mestimator\u001B[38;5;241m.\u001B[39mfit(X, y)\n\u001B[1;32m    476\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m--> 477\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mPlease check your X and y variable. The provided \u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m    478\u001B[0m                      \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mestimator cannot be fitted to your data.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m'\u001B[39m \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mstr\u001B[39m(e))\n\u001B[1;32m    479\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    480\u001B[0m     imp \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mestimator\u001B[38;5;241m.\u001B[39mfeature_importances_\n",
      "\u001B[0;31mValueError\u001B[0m: Please check your X and y variable. The provided estimator cannot be fitted to your data.\nnum_boost_round must be greater than 0. Got -1341."
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "396a13c35541c114"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
