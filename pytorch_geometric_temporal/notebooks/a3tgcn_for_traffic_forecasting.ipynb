{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-26T14:44:28.669393Z",
     "iopub.status.busy": "2021-12-26T14:44:28.668621Z",
     "iopub.status.idle": "2021-12-26T14:44:36.833339Z",
     "shell.execute_reply": "2021-12-26T14:44:36.832761Z",
     "shell.execute_reply.started": "2021-12-26T14:27:21.629074Z"
    },
    "papermill": {
     "duration": 8.187854,
     "end_time": "2021-12-26T14:44:36.833462",
     "exception": false,
     "start_time": "2021-12-26T14:44:28.645608",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-11-24T16:10:45.604476Z",
     "start_time": "2025-11-24T16:10:43.729996Z"
    }
   },
   "source": [
    "import os\n",
    "import joblib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric_temporal.nn.recurrent import A3TGCN2\n",
    "from torch_geometric_temporal.signal import temporal_signal_split\n",
    "\n",
    "# GPU support\n",
    "DEVICE = torch.device('cuda') # cuda\n",
    "shuffle=True\n",
    "batch_size = 32"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-24T16:10:46.824613Z",
     "start_time": "2025-11-24T16:10:46.285767Z"
    }
   },
   "cell_type": "code",
   "source": [
    "path_sys = '/media/sider/data' if os.path.exists('/media/sider/data') else '/home/smartrue'\n",
    "path_data = os.path.join(path_sys, 'Dropbox/current_codes/PycharmProjects/AdmieRP_train/DATA')\n",
    "\n",
    "parks = joblib.load(os.path.join(path_data, 'parks_static_info.pickle'))"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-24T16:51:52.498235Z",
     "start_time": "2025-11-24T16:51:52.495267Z"
    }
   },
   "cell_type": "code",
   "source": [
    "rated = np.array([p['rated'] for p in parks])\n",
    "rated"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([38.      ,  9.35    , 18.7     , 16.4724  , 28.3521  , 14.5383  ,\n",
       "       16.1     , 41.2986  , 28.8     , 14.4     ,  4.8846  , 16.      ,\n",
       "       20.24505 , 10.2648  ,  2.2848  , 22.64325 , 10.19235 , 10.899   ,\n",
       "        8.8809  , 16.9785  , 19.3809  , 15.      , 21.00105 , 14.55    ,\n",
       "       18.      ,  3.2361  , 24.3     , 14.4     , 14.4     , 58.      ,\n",
       "       18.      ,  3.57    , 42.      , 17.50455 ,  3.44505 , 43.26735 ,\n",
       "        6.5247  ,  3.22455 , 10.82025 , 24.51015 , 18.91155 , 24.4335  ,\n",
       "        8.4     , 38.183775, 70.98315 , 68.7015  , 42.      , 42.      ,\n",
       "       27.      , 21.15    , 18.8     , 42.3     , 42.903   ,  8.4     ,\n",
       "       18.      , 24.      , 12.0771  , 65.4     , 54.      , 37.35375 ,\n",
       "       17.      , 17.1738  , 28.8     ,  5.25    , 28.8     , 34.5807  ,\n",
       "       27.6     , 52.23855 , 50.      , 41.8     ,  4.3554  , 10.8     ,\n",
       "       26.9031  , 21.6     , 10.8     , 35.007   , 12.      ,  3.60465 ,\n",
       "       40.      ,  7.2     ,  5.4     , 89.43795 , 33.      ,  6.9111  ,\n",
       "       12.      ,  6.86175 , 37.8168  , 10.35    ,  6.98565 ,  2.99    ,\n",
       "       25.41525 ,  6.5079  , 21.6405  , 37.49445 , 63.      , 20.      ,\n",
       "       36.96    , 52.20915 , 28.2975  , 14.      , 35.4     , 44.625   ,\n",
       "       24.15945 ,  7.2     , 17.0709  ,  8.19105 ,  9.71145 , 12.0036  ,\n",
       "        9.6     ,  8.4462  , 24.      ,  8.39685 , 49.8309  , 34.5     ,\n",
       "        9.2     , 42.1953  , 22.      , 24.      ,  4.24305 ,  7.03815 ,\n",
       "       12.5769  , 29.9     , 25.3     , 31.8     , 54.0603  , 58.5123  ,\n",
       "       31.5     , 94.5     , 63.      , 15.31845 , 16.1931  , 24.42    ,\n",
       "        8.6646  , 33.6     , 48.      , 29.21625 , 19.551   , 14.6244  ,\n",
       "       31.5735  , 14.66325 , 31.41705 , 45.19515 , 12.      , 16.1     ,\n",
       "       25.3     , 36.768375, 26.      , 38.44995 , 35.95305 , 13.98705 ,\n",
       "        3.      , 15.      , 13.2783  , 25.3428  , 23.1     , 40.3599  ,\n",
       "       16.5417  , 14.9     , 44.      , 54.      , 67.2     , 54.      ,\n",
       "       28.2429  , 19.8     , 11.9742  , 18.375   , 21.21105 , 18.      ,\n",
       "        7.5033  ,  6.7977  , 12.2325  , 20.2398  , 10.8     , 42.9     ,\n",
       "       14.4     , 27.6     , 28.9     , 43.76925 , 43.76925 ])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 52
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.016367,
     "end_time": "2021-12-26T14:44:36.867084",
     "exception": false,
     "start_time": "2021-12-26T14:44:36.850717",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<h1>\n",
    "<center>A3T-GCN: Attention Temporal Graph\n",
    "Convolutional Network for Traffic Forecasting</center>\n",
    "</h1>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.028442,
     "end_time": "2021-12-26T14:44:36.914189",
     "exception": false,
     "start_time": "2021-12-26T14:44:36.885747",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Dataset\n",
    "- Traffic forecasting dataset based on Los Angeles Metropolitan traffic \n",
    "- 207 loop detectors on highways\n",
    "- March 2012 - June 2012\n",
    "- From the paper: Diffusion Convolutional Recurrent Neural Network\n"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-24T16:32:38.360578Z",
     "start_time": "2025-11-24T16:32:38.287120Z"
    }
   },
   "cell_type": "code",
   "source": [
    "spatial = []\n",
    "for i, park in enumerate(parks):\n",
    "    df = pd.DataFrame([[park['name'], i, park['lat'], park['long']]],\n",
    "                      columns=['name', 'id', 'latitude', 'longitude'])\n",
    "    spatial.append(df)\n",
    "spatial = pd.concat(spatial, ignore_index=True)\n",
    "spatial.set_index('name', inplace=True)\n",
    "edges = []\n",
    "edges_weights = []\n",
    "for i, park in enumerate(parks):\n",
    "    coordinates = spatial.loc[park['name']]\n",
    "    variables = park['variables']\n",
    "    variables = pd.DataFrame(variables, columns=['id', 'name']).sort_values(by='id')['name'].values\n",
    "    for feature in variables:\n",
    "        tag = feature.split('_')[-1]\n",
    "        name = '_'.join(feature.split('_')[:-1])\n",
    "        coord_temp = spatial.loc[name]\n",
    "        edges.append([i, coord_temp['id']])\n",
    "        edges_weights.append(np.sqrt((coordinates['latitude'] - coord_temp['latitude'])**2 + (coordinates['longitude'] - coord_temp['longitude'])**2))"
   ],
   "outputs": [],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-24T16:32:39.023402Z",
     "start_time": "2025-11-24T16:32:39.021573Z"
    }
   },
   "cell_type": "code",
   "source": [
    "edges = np.array(edges).T\n",
    "edges_weights = np.array(edges_weights).T"
   ],
   "outputs": [],
   "execution_count": 38
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-26T14:44:36.984196Z",
     "iopub.status.busy": "2021-12-26T14:44:36.983350Z",
     "iopub.status.idle": "2021-12-26T14:44:42.177982Z",
     "shell.execute_reply": "2021-12-26T14:44:42.177369Z",
     "shell.execute_reply.started": "2021-12-26T14:27:29.422377Z"
    },
    "papermill": {
     "duration": 5.23249,
     "end_time": "2021-12-26T14:44:42.178137",
     "exception": false,
     "start_time": "2021-12-26T14:44:36.945647",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-11-24T16:11:12.791389Z",
     "start_time": "2025-11-24T16:10:50.244517Z"
    }
   },
   "source": [
    "from torch_geometric_temporal.dataset.admie_ds import ADMIEDataset\n",
    "\n",
    "\n",
    "from ADMIE.configuration.config_input_data import (variables, TARGET_VARIABLE)\n",
    "variables_template = variables()\n",
    "dataset_train = ADMIEDataset(\n",
    "            path_data,\n",
    "            variables_template,\n",
    "            TARGET_VARIABLE,\n",
    "            rated,\n",
    "            task='train')\n",
    "dataset_val = ADMIEDataset(\n",
    "            path_data,\n",
    "            variables_template,\n",
    "            TARGET_VARIABLE,\n",
    "            rated,\n",
    "            task='val')\n",
    "dataset_test = ADMIEDataset(\n",
    "            path_data,\n",
    "            variables_template,\n",
    "            TARGET_VARIABLE,\n",
    "            rated,\n",
    "            task='test')\n",
    "print(\"Dataset type:  \", dataset_train)\n",
    "print(next(iter(dataset_train))) # Show first sample"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 280447/280447 [00:06<00:00, 40320.39it/s]\n",
      "100%|██████████| 280447/280447 [00:06<00:00, 40369.33it/s]\n",
      "100%|██████████| 280447/280447 [00:06<00:00, 40321.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset type:   <torch_geometric_temporal.dataset.admie_ds.ADMIEDataset object at 0x718077291f10>\n",
      "(tensor([[[0.0000e+00, 5.6944e+00, 5.6944e+00,  ..., 6.3953e+00,\n",
      "          6.4637e+00, 6.6574e+00],\n",
      "         [0.0000e+00, 1.6319e+02, 1.6319e+02,  ..., 1.6723e+02,\n",
      "          1.6846e+02, 1.6846e+02]],\n",
      "\n",
      "        [[0.0000e+00, 5.9897e+00, 5.9897e+00,  ..., 3.0085e+00,\n",
      "          2.3932e+00, 2.1197e+00],\n",
      "         [0.0000e+00, 3.3618e+01, 3.0382e+01,  ..., 2.2576e+01,\n",
      "          1.0878e+01, 5.8081e+01]],\n",
      "\n",
      "        [[0.0000e+00, 8.0000e+00, 8.0000e+00,  ..., 4.0342e+00,\n",
      "          4.1618e+00, 4.0205e+00],\n",
      "         [0.0000e+00, 3.3196e+01, 3.5587e+01,  ..., 1.6387e+01,\n",
      "          1.2284e+01, 5.4048e+01]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.0000e+00, 8.9829e+00, 8.9829e+00,  ..., 6.9829e+00,\n",
      "          6.9829e+00, 6.4496e+00],\n",
      "         [0.0000e+00, 8.0917e+01, 7.0555e+01,  ..., 7.9874e+01,\n",
      "          8.3542e+01, 8.4687e+01]],\n",
      "\n",
      "        [[0.0000e+00, 1.2308e+00, 0.0000e+00,  ..., 1.2308e-01,\n",
      "          0.0000e+00, 8.2051e-01],\n",
      "         [0.0000e+00, 5.0305e+01, 5.0305e+01,  ..., 7.9618e+01,\n",
      "          7.9618e+01, 7.8881e+01]],\n",
      "\n",
      "        [[0.0000e+00, 4.8155e+00, 4.8155e+00,  ..., 4.2599e+00,\n",
      "          4.2599e+00, 4.3780e+00],\n",
      "         [0.0000e+00, 5.0305e+01, 5.0305e+01,  ..., 7.9618e+01,\n",
      "          7.9618e+01, 7.8881e+01]]], dtype=torch.float64), tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]]], dtype=torch.float64), tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]], dtype=torch.float64))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.019118,
     "end_time": "2021-12-26T14:44:45.325730",
     "exception": false,
     "start_time": "2021-12-26T14:44:45.306612",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Creating DataLoaders\n"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-24T16:11:18.230715Z",
     "start_time": "2025-11-24T16:11:18.228672Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch.utils.data import DataLoader\n",
    "dataloader_train = DataLoader(dataset_train, shuffle=shuffle, batch_size=batch_size)\n",
    "dataloader_val = DataLoader(dataset_val, shuffle=shuffle, batch_size=batch_size)\n",
    "dataloader_test = DataLoader(dataset_test, shuffle=shuffle, batch_size=batch_size)"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-26T14:45:16.886780Z",
     "iopub.status.busy": "2021-12-26T14:45:16.885865Z",
     "iopub.status.idle": "2021-12-26T14:45:17.010178Z",
     "shell.execute_reply": "2021-12-26T14:45:17.009681Z",
     "shell.execute_reply.started": "2021-12-26T14:28:07.974097Z"
    },
    "papermill": {
     "duration": 0.150197,
     "end_time": "2021-12-26T14:45:17.010312",
     "exception": false,
     "start_time": "2021-12-26T14:45:16.860115",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-11-24T16:11:29.306853Z",
     "start_time": "2025-11-24T16:11:29.292226Z"
    }
   },
   "source": "past, future, target = next(iter(dataloader_train))",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-24T16:11:33.830989Z",
     "start_time": "2025-11-24T16:11:33.828217Z"
    }
   },
   "cell_type": "code",
   "source": "past.shape\n",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 179, 2, 21])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.018593,
     "end_time": "2021-12-26T14:45:17.047998",
     "exception": false,
     "start_time": "2021-12-26T14:45:17.029405",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Model\n",
    "\n",
    "Which model to choose depends on which time-series task you work on. \n",
    "\n",
    "- A3TGCN is an extension of TGCN that uses attention \n",
    "- The spatial aggregation uses GCN, the temporal aggregation a GRU\n",
    "- We can pass in periods to get an embedding for several timesteps\n",
    "- This embedding can be used to predict several steps into the future = output dimension\n",
    "- We could also do this in a loop and feed it again into the model (would be autoregressive)\n",
    "- There is only one block here. Other layers also allow stacking???\n",
    "\n",
    "<html>\n",
    "<img src=\"https://i.ibb.co/WxrJQbc/a3tgcn.png\", height=\"300\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.018337,
     "end_time": "2021-12-26T14:45:17.085185",
     "exception": false,
     "start_time": "2021-12-26T14:45:17.066848",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# TGCN model\n",
    "A temporal GCN (T-GCN) model was constructed by combining GCN and GRU. \n",
    "\n",
    "n historical time series traffic data were inputted into the T-GCN model to obtain n hidden states (h) that covered spatiotemporal characteristics:{h(t−n), · · · , h(t−1), h(t)}\n",
    "\n",
    "\n",
    "ut = σ(Wu ∗ (GC(A, Xt), ht−1)) \n",
    "\n",
    "rt = σ(Wr ∗ (GC(A, Xt), ht−1)) \n",
    "\n",
    "ct = tanh(Wc ∗ (GC(A, Xt), (rt ∗ ht−1)))\n",
    "\n",
    "ht = ut ∗ ht−1 + (1 − ut) ∗ ct) \n",
    "\n",
    "\n",
    "Then, the hidden states were inputted into the attention model to determine the context vector that covers the global traffic variation information. Particularly, the weight of each h was calculated by Softmax using a multilayer perception:{at−n, · · · , at−1, at}.The context vector that covers global traffic variation information is calculated by the weighted sum. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.018547,
     "end_time": "2021-12-26T14:45:17.122157",
     "exception": false,
     "start_time": "2021-12-26T14:45:17.103610",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# A3TGCN Model\n",
    "The A3TGCN is an extention of the TGCN model by adding an attention mechanism.\n",
    "\n",
    "The attention mechanism was introduced to re-weight the influence of historical traffic states and thus to capture the global variation trends of traffic state"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-26T14:45:17.167230Z",
     "iopub.status.busy": "2021-12-26T14:45:17.166722Z",
     "iopub.status.idle": "2021-12-26T14:45:17.181682Z",
     "shell.execute_reply": "2021-12-26T14:45:17.181219Z",
     "shell.execute_reply.started": "2021-12-26T14:28:08.105670Z"
    },
    "papermill": {
     "duration": 0.041032,
     "end_time": "2021-12-26T14:45:17.181766",
     "exception": false,
     "start_time": "2021-12-26T14:45:17.140734",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-11-24T16:37:02.683081Z",
     "start_time": "2025-11-24T16:37:02.680849Z"
    }
   },
   "source": [
    "class TemporalGNN(torch.nn.Module):\n",
    "    def __init__(self, node_features, periods, batch_size):\n",
    "        super(TemporalGNN, self).__init__()\n",
    "        # Attention Temporal Graph Convolutional Cell\n",
    "        self.tgnn = A3TGCN2(in_channels=node_features,  out_channels=32, periods=periods,batch_size=batch_size) # node_features=2, periods=12\n",
    "        # Equals single-shot prediction\n",
    "        self.linear = torch.nn.Linear(32, periods)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_weights):\n",
    "        \"\"\"\n",
    "        x = Node features for T time steps\n",
    "        edge_index = Graph edge indices\n",
    "        \"\"\"\n",
    "        h = self.tgnn(x, edge_index, edge_weights) # x [b, 207, 2, 12]  returns h [b, 207, 12]\n",
    "        h = F.relu(h) \n",
    "        h = self.linear(h)\n",
    "        return h\n"
   ],
   "outputs": [],
   "execution_count": 46
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-24T16:37:03.361304Z",
     "start_time": "2025-11-24T16:37:03.358747Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class BiTemporalGNN(torch.nn.Module):\n",
    "    def __init__(self,):\n",
    "        super(BiTemporalGNN, self).__init__()\n",
    "        # Attention Temporal Graph Convolutional Cell\n",
    "        self.bitgnn1 = TemporalGNN(node_features=2, periods=21, batch_size=128) # node_features=2, periods=12\n",
    "        self.bitgnn2 = TemporalGNN(node_features=2, periods=20, batch_size=128) # node_features=2, periods=12\n",
    "        # Equals single-shot prediction\n",
    "        self.linear = torch.nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, past, future, edge_index, edges_weights):\n",
    "        \"\"\"\n",
    "        x = Node features for T time steps\n",
    "        edge_index = Graph edge indices\n",
    "        \"\"\"\n",
    "        h1 = self.bitgnn1(past, edge_index, edges_weights) # x [b, 207, 2, 12]  returns h [b, 207, 12]\n",
    "        h2 = self.bitgnn2(future, edge_index, edges_weights) # x [b, 207, 2, 12]  returns h [b, 207, 12]\n",
    "        h = F.relu(torch.cat([h1, h2], dim=-1))\n",
    "        h = self.linear(h)\n",
    "        return h"
   ],
   "outputs": [],
   "execution_count": 47
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.01927,
     "end_time": "2021-12-26T14:45:17.220204",
     "exception": false,
     "start_time": "2021-12-26T14:45:17.200934",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-26T14:45:17.274663Z",
     "iopub.status.busy": "2021-12-26T14:45:17.273722Z",
     "iopub.status.idle": "2021-12-26T14:45:17.301756Z",
     "shell.execute_reply": "2021-12-26T14:45:17.300951Z",
     "shell.execute_reply.started": "2021-12-25T23:05:32.708582Z"
    },
    "papermill": {
     "duration": 0.059799,
     "end_time": "2021-12-26T14:45:17.301931",
     "exception": false,
     "start_time": "2021-12-26T14:45:17.242132",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-11-24T16:37:04.714090Z",
     "start_time": "2025-11-24T16:37:04.703627Z"
    }
   },
   "source": [
    "\n",
    "# Create model and optimizers\n",
    "model = BiTemporalGNN().to(DEVICE)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "# edges = torch.from_numpy(edges).type(torch.LongTensor).to(DEVICE)\n",
    "# edges_weights = torch.from_numpy(edges_weights).type(torch.FloatTensor).to(torch.float32).to(DEVICE)\n",
    "\n",
    "print('Net\\'s state_dict:')\n",
    "total_param = 0\n",
    "for param_tensor in model.state_dict():\n",
    "    print(param_tensor, '\\t', model.state_dict()[param_tensor].size())\n",
    "    total_param += np.prod(model.state_dict()[param_tensor].size())\n",
    "print('Net\\'s total params:', total_param)\n",
    "#--------------------------------------------------\n",
    "print('Optimizer\\'s state_dict:')\n",
    "for var_name in optimizer.state_dict():\n",
    "    print(var_name, '\\t', optimizer.state_dict()[var_name])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net's state_dict:\n",
      "bitgnn1.tgnn._attention \t torch.Size([21])\n",
      "bitgnn1.tgnn._base_tgcn.conv_z.bias \t torch.Size([32])\n",
      "bitgnn1.tgnn._base_tgcn.conv_z.lin.weight \t torch.Size([32, 2])\n",
      "bitgnn1.tgnn._base_tgcn.linear_z.weight \t torch.Size([32, 64])\n",
      "bitgnn1.tgnn._base_tgcn.linear_z.bias \t torch.Size([32])\n",
      "bitgnn1.tgnn._base_tgcn.conv_r.bias \t torch.Size([32])\n",
      "bitgnn1.tgnn._base_tgcn.conv_r.lin.weight \t torch.Size([32, 2])\n",
      "bitgnn1.tgnn._base_tgcn.linear_r.weight \t torch.Size([32, 64])\n",
      "bitgnn1.tgnn._base_tgcn.linear_r.bias \t torch.Size([32])\n",
      "bitgnn1.tgnn._base_tgcn.conv_h.bias \t torch.Size([32])\n",
      "bitgnn1.tgnn._base_tgcn.conv_h.lin.weight \t torch.Size([32, 2])\n",
      "bitgnn1.tgnn._base_tgcn.linear_h.weight \t torch.Size([32, 64])\n",
      "bitgnn1.tgnn._base_tgcn.linear_h.bias \t torch.Size([32])\n",
      "bitgnn1.linear.weight \t torch.Size([21, 32])\n",
      "bitgnn1.linear.bias \t torch.Size([21])\n",
      "bitgnn2.tgnn._attention \t torch.Size([20])\n",
      "bitgnn2.tgnn._base_tgcn.conv_z.bias \t torch.Size([32])\n",
      "bitgnn2.tgnn._base_tgcn.conv_z.lin.weight \t torch.Size([32, 2])\n",
      "bitgnn2.tgnn._base_tgcn.linear_z.weight \t torch.Size([32, 64])\n",
      "bitgnn2.tgnn._base_tgcn.linear_z.bias \t torch.Size([32])\n",
      "bitgnn2.tgnn._base_tgcn.conv_r.bias \t torch.Size([32])\n",
      "bitgnn2.tgnn._base_tgcn.conv_r.lin.weight \t torch.Size([32, 2])\n",
      "bitgnn2.tgnn._base_tgcn.linear_r.weight \t torch.Size([32, 64])\n",
      "bitgnn2.tgnn._base_tgcn.linear_r.bias \t torch.Size([32])\n",
      "bitgnn2.tgnn._base_tgcn.conv_h.bias \t torch.Size([32])\n",
      "bitgnn2.tgnn._base_tgcn.conv_h.lin.weight \t torch.Size([32, 2])\n",
      "bitgnn2.tgnn._base_tgcn.linear_h.weight \t torch.Size([32, 64])\n",
      "bitgnn2.tgnn._base_tgcn.linear_h.bias \t torch.Size([32])\n",
      "bitgnn2.linear.weight \t torch.Size([20, 32])\n",
      "bitgnn2.linear.bias \t torch.Size([20])\n",
      "linear.weight \t torch.Size([1, 64])\n",
      "linear.bias \t torch.Size([1])\n",
      "Net's total params: 14515\n",
      "Optimizer's state_dict:\n",
      "state \t {}\n",
      "param_groups \t [{'lr': 0.001, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False, 'maximize': False, 'foreach': None, 'capturable': False, 'differentiable': False, 'fused': None, 'decoupled_weight_decay': False, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]}]\n"
     ]
    }
   ],
   "execution_count": 48
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.020038,
     "end_time": "2021-12-26T14:45:17.343900",
     "exception": false,
     "start_time": "2021-12-26T14:45:17.323862",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Loading the graph once \n",
    "because it's a static graph"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-26T14:45:17.437982Z",
     "iopub.status.busy": "2021-12-26T14:45:17.437484Z",
     "iopub.status.idle": "2021-12-26T14:46:13.161937Z",
     "shell.execute_reply": "2021-12-26T14:46:13.161017Z",
     "shell.execute_reply.started": "2021-12-25T23:05:32.751777Z"
    },
    "papermill": {
     "duration": 55.751589,
     "end_time": "2021-12-26T14:46:13.162096",
     "exception": false,
     "start_time": "2021-12-26T14:45:17.410507",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-11-24T16:37:06.137001Z",
     "start_time": "2025-11-24T16:37:05.983377Z"
    }
   },
   "source": [
    "model.train()\n",
    "\n",
    "for epoch in range(1):\n",
    "    step = 0\n",
    "    loss_list = []\n",
    "    for past, future, labels in dataloader_train:\n",
    "        past = past.to(torch.float32).to(DEVICE)\n",
    "        future = future.to(torch.float32).to(DEVICE)\n",
    "        labels = labels.to(torch.float32).to(DEVICE)\n",
    "        y_hat = model(past, future, edges, edges_weights)         # Get model predictions\n",
    "        loss = loss_fn(y_hat, labels) # Mean squared error #loss = torch.mean((y_hat-labels)**2)  sqrt to change it to rmse\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        step= step + 1\n",
    "        loss_list.append(loss.item())\n",
    "        if step % 100 == 0 :\n",
    "            print(sum(loss_list)/len(loss_list))\n",
    "    print(\"Epoch {} train RMSE: {:.4f}\".format(epoch, sum(loss_list)/len(loss_list)))"
   ],
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (5728x41 and 64x1)",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mRuntimeError\u001B[39m                              Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[49]\u001B[39m\u001B[32m, line 10\u001B[39m\n\u001B[32m      8\u001B[39m future = future.to(torch.float32).to(DEVICE)\n\u001B[32m      9\u001B[39m labels = labels.to(torch.float32).to(DEVICE)\n\u001B[32m---> \u001B[39m\u001B[32m10\u001B[39m y_hat = \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpast\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfuture\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43medges\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43medges_weights\u001B[49m\u001B[43m)\u001B[49m         \u001B[38;5;66;03m# Get model predictions\u001B[39;00m\n\u001B[32m     11\u001B[39m loss = loss_fn(y_hat, labels) \u001B[38;5;66;03m# Mean squared error #loss = torch.mean((y_hat-labels)**2)  sqrt to change it to rmse\u001B[39;00m\n\u001B[32m     12\u001B[39m loss.backward()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/media/sider/data/Dropbox/current_codes/PycharmProjects/Training_phase/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1751\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1749\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1750\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1751\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/media/sider/data/Dropbox/current_codes/PycharmProjects/Training_phase/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1762\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1757\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1758\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1759\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1760\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1761\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1762\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1764\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1765\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[47]\u001B[39m\u001B[32m, line 18\u001B[39m, in \u001B[36mBiTemporalGNN.forward\u001B[39m\u001B[34m(self, past, future, edge_index, edges_weights)\u001B[39m\n\u001B[32m     16\u001B[39m h2 = \u001B[38;5;28mself\u001B[39m.bitgnn2(future, edge_index, edges_weights) \u001B[38;5;66;03m# x [b, 207, 2, 12]  returns h [b, 207, 12]\u001B[39;00m\n\u001B[32m     17\u001B[39m h = F.relu(torch.cat([h1, h2], dim=-\u001B[32m1\u001B[39m))\n\u001B[32m---> \u001B[39m\u001B[32m18\u001B[39m h = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mlinear\u001B[49m\u001B[43m(\u001B[49m\u001B[43mh\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     19\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m h\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/media/sider/data/Dropbox/current_codes/PycharmProjects/Training_phase/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1751\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1749\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1750\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1751\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/media/sider/data/Dropbox/current_codes/PycharmProjects/Training_phase/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1762\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1757\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1758\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1759\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1760\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1761\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1762\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1764\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1765\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/media/sider/data/Dropbox/current_codes/PycharmProjects/Training_phase/.venv/lib/python3.11/site-packages/torch/nn/modules/linear.py:125\u001B[39m, in \u001B[36mLinear.forward\u001B[39m\u001B[34m(self, input)\u001B[39m\n\u001B[32m    124\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) -> Tensor:\n\u001B[32m--> \u001B[39m\u001B[32m125\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[43m.\u001B[49m\u001B[43mlinear\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mbias\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[31mRuntimeError\u001B[39m: mat1 and mat2 shapes cannot be multiplied (5728x41 and 64x1)"
     ]
    }
   ],
   "execution_count": 49
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.022713,
     "end_time": "2021-12-26T14:46:13.250898",
     "exception": false,
     "start_time": "2021-12-26T14:46:13.228185",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Evaluation\n",
    "\n",
    "- Lets get some sample predictions for a specific horizon (e.g. 288/12 = 24 hours)\n",
    "- The model always gets one hour and needs to predict the next hour"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-26T14:46:13.301157Z",
     "iopub.status.busy": "2021-12-26T14:46:13.300285Z",
     "iopub.status.idle": "2021-12-26T14:46:23.410533Z",
     "shell.execute_reply": "2021-12-26T14:46:23.411181Z",
     "shell.execute_reply.started": "2021-12-25T22:37:06.708018Z"
    },
    "papermill": {
     "duration": 10.1385,
     "end_time": "2021-12-26T14:46:23.411366",
     "exception": false,
     "start_time": "2021-12-26T14:46:13.272866",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "model.eval()\n",
    "step = 0\n",
    "# Store for analysis\n",
    "total_loss = []\n",
    "for past, future, labels in dataloader_train:\n",
    "    past = past.to(torch.float32).to(DEVICE)\n",
    "    future = future.to(torch.float32).to(DEVICE)\n",
    "    labels = labels.to(torch.float32).to(DEVICE)\n",
    "    y_hat = model(past, future, edges, edges_weights)\n",
    "    # Mean squared error\n",
    "    loss = loss_fn(y_hat, labels)\n",
    "    total_loss.append(loss.item())\n",
    "    # Store for analysis below\n",
    "    #test_labels.append(labels)\n",
    "    #predictions.append(y_hat)\n",
    "    \n",
    "\n",
    "print(\"Test MSE: {:.4f}\".format(sum(total_loss)/len(total_loss)))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.021809,
     "end_time": "2021-12-26T14:46:23.456452",
     "exception": false,
     "start_time": "2021-12-26T14:46:23.434643",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Visualization\n",
    "\n",
    "- The further away the point in time is, the worse the predictions get\n",
    "- Predictions shape: [num_data_points, num_sensors, num_timesteps]"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-26T14:46:23.506391Z",
     "iopub.status.busy": "2021-12-26T14:46:23.505530Z",
     "iopub.status.idle": "2021-12-26T14:46:23.511700Z",
     "shell.execute_reply": "2021-12-26T14:46:23.512123Z",
     "shell.execute_reply.started": "2021-12-25T19:05:28.569378Z"
    },
    "papermill": {
     "duration": 0.0341,
     "end_time": "2021-12-26T14:46:23.512227",
     "exception": false,
     "start_time": "2021-12-26T14:46:23.478127",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "sensor = 123\n",
    "timestep = 11 \n",
    "preds = np.asarray([pred[sensor][timestep].detach().cpu().numpy() for pred in y_hat])\n",
    "labs  = np.asarray([label[sensor][timestep].cpu().numpy() for label in labels])\n",
    "print(\"Data points:,\", preds.shape)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-26T14:46:23.572365Z",
     "iopub.status.busy": "2021-12-26T14:46:23.571817Z",
     "iopub.status.idle": "2021-12-26T14:46:23.787013Z",
     "shell.execute_reply": "2021-12-26T14:46:23.786488Z",
     "shell.execute_reply.started": "2021-12-25T19:05:29.188303Z"
    },
    "papermill": {
     "duration": 0.251559,
     "end_time": "2021-12-26T14:46:23.787119",
     "exception": false,
     "start_time": "2021-12-26T14:46:23.535560",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "plt.figure(figsize=(20,5))\n",
    "sns.lineplot(data=preds, label=\"pred\")\n",
    "sns.lineplot(data=labs, label=\"true\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "papermill": {
     "duration": 0.023746,
     "end_time": "2021-12-26T14:46:23.836554",
     "exception": false,
     "start_time": "2021-12-26T14:46:23.812808",
     "status": "completed"
    },
    "tags": []
   },
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 159.672275,
   "end_time": "2021-12-26T14:46:24.067327",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-12-26T14:43:44.395052",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
